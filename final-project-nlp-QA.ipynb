{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12093802,"sourceType":"datasetVersion","datasetId":7613195}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Final Project**\n\n## **Problem stament :**     \n\nThe widespread dissemination of fake news and propaganda presents serious societal risks, including the erosion of public trust, political polarization, manipulation of elections, and the spread of harmful misinformation during crises such as pandemics or conflicts. From an NLP perspective, detecting fake news is fraught with challenges. Linguistically, fake news often mimics the tone and structure of legitimate journalism, making it difficult to distinguish using surface-level features. The absence of reliable and up-to-date labeled datasets, especially across multiple languages and regions, hampers the effectiveness of supervised learning models. Additionally, the dynamic and adversarial nature of misinformation means that malicious actors constantly evolve their language and strategies to bypass detection systems. Cultural context, sarcasm, satire, and implicit bias further complicate automated analysis. Moreover, NLP models risk amplifying biases present in training data, leading to unfair classifications and potential censorship of legitimate content. These challenges underscore the need for cautious, context-aware approaches, as the failure to address them can inadvertently contribute to misinformation, rather than mitigate it.\n\n\n\nUse datasets in link : https://drive.google.com/drive/folders/1mrX3vPKhEzxG96OCPpCeh9F8m_QKCM4z?usp=sharing\nto complete requirement.\n\n## **About dataset:**\n\n* **True Articles**:\n\n  * **File**: `MisinfoSuperset_TRUE.csv`\n  * **Sources**:\n\n    * Reputable media outlets like **Reuters**, **The New York Times**, **The Washington Post**, etc.\n\n* **Fake/Misinformation/Propaganda Articles**:\n\n  * **File**: `MisinfoSuperset_FAKE.csv`\n  * **Sources**:\n\n    * **American right-wing extremist websites** (e.g., Redflag Newsdesk, Breitbart, Truth Broadcast Network)\n    * **Public dataset** from:\n\n      * Ahmed, H., Traore, I., & Saad, S. (2017): \"Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques\" *(Springer LNCS 10618)*\n\n\n\n## **Requirement**\n\nA team consisting of three members must complete a project that involves applying the methods learned from the beginning of the course up to the present. The team is expected to follow and document the entire machine learning workflow, which includes the following steps:\n\n1. **Data Preprocessing**: Clean and prepare the dataset,etc.\n\n2. **Exploratory Data Analysis (EDA)**: Explore and visualize the data.\n\n3. **Model Building**: Select and build one or more machine learning models suitable for the problem at hand.\n\n4. **Hyperparameter set up**: Set and adjust the model's hyperparameters using appropriate methods to improve performance.\n\n5. **Model Training**: Train the model(s) on the training dataset.\n\n6. **Performance Evaluation**: Evaluate the trained model(s) using appropriate metrics (e.g., accuracy, precision, recall, F1-score, confusion matrix, etc.) and validate their performance on unseen data.\n\n7. **Conclusion**: Summarize the results, discuss the model's strengths and weaknesses, and suggest possible improvements or future work.\n\n\n\n","metadata":{"id":"eFCzIBshcHmg"}},{"cell_type":"markdown","source":"# Read dataset","metadata":{}},{"cell_type":"code","source":"!pip install contractions","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:02.347898Z","iopub.execute_input":"2025-06-16T07:43:02.348371Z","iopub.status.idle":"2025-06-16T07:43:06.908675Z","shell.execute_reply.started":"2025-06-16T07:43:02.348331Z","shell.execute_reply":"2025-06-16T07:43:06.907956Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting contractions\n  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting textsearch>=0.0.21 (from contractions)\n  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting anyascii (from textsearch>=0.0.21->contractions)\n  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\nCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nDownloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\nDownloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\nDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\nSuccessfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install langdetect","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:43:06.910391Z","iopub.execute_input":"2025-06-16T07:43:06.910716Z","iopub.status.idle":"2025-06-16T07:43:12.166003Z","shell.execute_reply.started":"2025-06-16T07:43:06.910686Z","shell.execute_reply":"2025-06-16T07:43:12.165298Z"}},"outputs":[{"name":"stdout","text":"Collecting langdetect\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\nBuilding wheels for collected packages: langdetect\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=06b9ac84fb4a01e47ef999a6defdf0bb71713b48245f44e3bd032e87063abea1\n  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\nSuccessfully built langdetect\nInstalling collected packages: langdetect\nSuccessfully installed langdetect-1.0.9\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport contractions\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom transformers import BertTokenizer\n\nimport html\nimport quopri\nimport emoji\nfrom bs4 import BeautifulSoup\nfrom langdetect import detect, LangDetectException","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:12.166936Z","iopub.execute_input":"2025-06-16T07:43:12.167153Z","iopub.status.idle":"2025-06-16T07:43:20.905919Z","shell.execute_reply.started":"2025-06-16T07:43:12.167128Z","shell.execute_reply":"2025-06-16T07:43:20.905381Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"true_df = pd.read_csv(\"/kaggle/input/misinfo/DataSet_Misinfo_TRUE.csv\")\ntrue_df","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:20.907548Z","iopub.execute_input":"2025-06-16T07:43:20.907968Z","iopub.status.idle":"2025-06-16T07:43:23.571846Z","shell.execute_reply.started":"2025-06-16T07:43:20.907948Z","shell.execute_reply":"2025-06-16T07:43:23.570963Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0                                               text\n0               0  The head of a conservative Republican faction ...\n1               1  Transgender people will be allowed for the fir...\n2               2  The special counsel investigation of links bet...\n3               3  Trump campaign adviser George Papadopoulos tol...\n4               4  President Donald Trump called on the U.S. Post...\n...           ...                                                ...\n34970       34970  Most conservatives who oppose marriage equalit...\n34971       34971  The freshman senator from Georgia quoted scrip...\n34972       34972  The State Department told the Republican Natio...\n34973       34973  ADDIS ABABA, Ethiopia —President Obama convene...\n34974       34974  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n\n[34975 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>The head of a conservative Republican faction ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Transgender people will be allowed for the fir...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>The special counsel investigation of links bet...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Trump campaign adviser George Papadopoulos tol...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>President Donald Trump called on the U.S. Post...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34970</th>\n      <td>34970</td>\n      <td>Most conservatives who oppose marriage equalit...</td>\n    </tr>\n    <tr>\n      <th>34971</th>\n      <td>34971</td>\n      <td>The freshman senator from Georgia quoted scrip...</td>\n    </tr>\n    <tr>\n      <th>34972</th>\n      <td>34972</td>\n      <td>The State Department told the Republican Natio...</td>\n    </tr>\n    <tr>\n      <th>34973</th>\n      <td>34973</td>\n      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n    </tr>\n    <tr>\n      <th>34974</th>\n      <td>34974</td>\n      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n    </tr>\n  </tbody>\n</table>\n<p>34975 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"fake_df = pd.read_csv(\"/kaggle/input/misinfo/DataSet_Misinfo_FAKE.csv\")\nfake_df","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:23.572583Z","iopub.execute_input":"2025-06-16T07:43:23.573083Z","iopub.status.idle":"2025-06-16T07:43:25.850785Z","shell.execute_reply.started":"2025-06-16T07:43:23.573063Z","shell.execute_reply":"2025-06-16T07:43:25.850202Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0                                               text\n0               0  Donald Trump just couldn t wish all Americans ...\n1               1  House Intelligence Committee Chairman Devin Nu...\n2               2  On Friday, it was revealed that former Milwauk...\n3               3  On Christmas day, Donald Trump announced that ...\n4               4  Pope Francis used his annual Christmas Day mes...\n...           ...                                                ...\n43637       44422  The USA wants to divide Syria.\\r\\n\\r\\nGreat Br...\n43638       44423  The Ukrainian coup d'etat cost the US nothing ...\n43639       44424  The European Parliament falsifies history by d...\n43640       44425  The European Parliament falsifies history by d...\n43641       44426  A leading FSB officer, Segey Beseda, said duri...\n\n[43642 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Donald Trump just couldn t wish all Americans ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>House Intelligence Committee Chairman Devin Nu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>On Friday, it was revealed that former Milwauk...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>On Christmas day, Donald Trump announced that ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Pope Francis used his annual Christmas Day mes...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43637</th>\n      <td>44422</td>\n      <td>The USA wants to divide Syria.\\r\\n\\r\\nGreat Br...</td>\n    </tr>\n    <tr>\n      <th>43638</th>\n      <td>44423</td>\n      <td>The Ukrainian coup d'etat cost the US nothing ...</td>\n    </tr>\n    <tr>\n      <th>43639</th>\n      <td>44424</td>\n      <td>The European Parliament falsifies history by d...</td>\n    </tr>\n    <tr>\n      <th>43640</th>\n      <td>44425</td>\n      <td>The European Parliament falsifies history by d...</td>\n    </tr>\n    <tr>\n      <th>43641</th>\n      <td>44426</td>\n      <td>A leading FSB officer, Segey Beseda, said duri...</td>\n    </tr>\n  </tbody>\n</table>\n<p>43642 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Delete order column\ntrue_df = true_df.drop('Unnamed: 0', axis=1)\nfake_df = fake_df.drop('Unnamed: 0', axis=1)","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:25.851591Z","iopub.execute_input":"2025-06-16T07:43:25.852174Z","iopub.status.idle":"2025-06-16T07:43:25.862179Z","shell.execute_reply.started":"2025-06-16T07:43:25.852141Z","shell.execute_reply":"2025-06-16T07:43:25.861675Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"true_df.info()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:25.862859Z","iopub.execute_input":"2025-06-16T07:43:25.863080Z","iopub.status.idle":"2025-06-16T07:43:25.894942Z","shell.execute_reply.started":"2025-06-16T07:43:25.863064Z","shell.execute_reply":"2025-06-16T07:43:25.894128Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 34975 entries, 0 to 34974\nData columns (total 1 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    34946 non-null  object\ndtypes: object(1)\nmemory usage: 273.4+ KB\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"fake_df.info()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:25.895695Z","iopub.execute_input":"2025-06-16T07:43:25.895900Z","iopub.status.idle":"2025-06-16T07:43:25.916045Z","shell.execute_reply.started":"2025-06-16T07:43:25.895883Z","shell.execute_reply":"2025-06-16T07:43:25.915390Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 43642 entries, 0 to 43641\nData columns (total 1 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    43642 non-null  object\ndtypes: object(1)\nmemory usage: 341.1+ KB\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"true_df.describe()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:25.916689Z","iopub.execute_input":"2025-06-16T07:43:25.916881Z","iopub.status.idle":"2025-06-16T07:43:26.031848Z","shell.execute_reply.started":"2025-06-16T07:43:25.916865Z","shell.execute_reply":"2025-06-16T07:43:26.031273Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                     text\ncount                                               34946\nunique                                              34526\ntop     Killing Obama administration rules, dismantlin...\nfreq                                                   58","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>34946</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>34526</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Killing Obama administration rules, dismantlin...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>58</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"fake_df.describe()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:26.034204Z","iopub.execute_input":"2025-06-16T07:43:26.034500Z","iopub.status.idle":"2025-06-16T07:43:26.126458Z","shell.execute_reply.started":"2025-06-16T07:43:26.034483Z","shell.execute_reply":"2025-06-16T07:43:26.125726Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                     text\ncount                                               43642\nunique                                              34078\ntop     Leave a Reply Click here to get more info on f...\nfreq                                                   38","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>43642</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>34078</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Leave a Reply Click here to get more info on f...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>38</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"- Xử lý giá trị null","metadata":{}},{"cell_type":"code","source":"true_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:26.127229Z","iopub.execute_input":"2025-06-16T07:43:26.127465Z","iopub.status.idle":"2025-06-16T07:43:26.138076Z","shell.execute_reply.started":"2025-06-16T07:43:26.127441Z","shell.execute_reply":"2025-06-16T07:43:26.137375Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"text    29\ndtype: int64"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"fake_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:26.138771Z","iopub.execute_input":"2025-06-16T07:43:26.138953Z","iopub.status.idle":"2025-06-16T07:43:26.158614Z","shell.execute_reply.started":"2025-06-16T07:43:26.138938Z","shell.execute_reply":"2025-06-16T07:43:26.157884Z"},"trusted":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"text    0\ndtype: int64"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"true_df = true_df.dropna()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:26.159460Z","iopub.execute_input":"2025-06-16T07:43:26.159724Z","iopub.status.idle":"2025-06-16T07:43:26.179902Z","shell.execute_reply.started":"2025-06-16T07:43:26.159702Z","shell.execute_reply":"2025-06-16T07:43:26.179383Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"- Xử lý giá trị duplicate","metadata":{}},{"cell_type":"code","source":"true_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:26.180607Z","iopub.execute_input":"2025-06-16T07:43:26.180843Z","iopub.status.idle":"2025-06-16T07:43:26.198305Z","shell.execute_reply.started":"2025-06-16T07:43:26.180826Z","shell.execute_reply":"2025-06-16T07:43:26.197651Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"420"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"fake_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:26.198997Z","iopub.execute_input":"2025-06-16T07:43:26.199510Z","iopub.status.idle":"2025-06-16T07:43:26.218391Z","shell.execute_reply.started":"2025-06-16T07:43:26.199486Z","shell.execute_reply":"2025-06-16T07:43:26.217722Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"9564"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"true_df = true_df.drop_duplicates()\nfake_df = fake_df.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:26.219107Z","iopub.execute_input":"2025-06-16T07:43:26.219313Z","iopub.status.idle":"2025-06-16T07:43:26.243928Z","shell.execute_reply.started":"2025-06-16T07:43:26.219298Z","shell.execute_reply":"2025-06-16T07:43:26.243128Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"- Thêm label và gộp 2 tập dữ liệu","metadata":{}},{"cell_type":"code","source":"true_df['label'] = 1\nfake_df['label'] = 0\n\ndf = pd.concat([true_df, fake_df], ignore_index=True)\ndf","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:26.244629Z","iopub.execute_input":"2025-06-16T07:43:26.244898Z","iopub.status.idle":"2025-06-16T07:43:26.256130Z","shell.execute_reply.started":"2025-06-16T07:43:26.244881Z","shell.execute_reply":"2025-06-16T07:43:26.255507Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                                    text  label\n0      The head of a conservative Republican faction ...      1\n1      Transgender people will be allowed for the fir...      1\n2      The special counsel investigation of links bet...      1\n3      Trump campaign adviser George Papadopoulos tol...      1\n4      President Donald Trump called on the U.S. Post...      1\n...                                                  ...    ...\n68599  Apparently, the new Kyiv government is in a hu...      0\n68600  The USA wants to divide Syria.\\r\\n\\r\\nGreat Br...      0\n68601  The Ukrainian coup d'etat cost the US nothing ...      0\n68602  The European Parliament falsifies history by d...      0\n68603  A leading FSB officer, Segey Beseda, said duri...      0\n\n[68604 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The head of a conservative Republican faction ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Transgender people will be allowed for the fir...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The special counsel investigation of links bet...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trump campaign adviser George Papadopoulos tol...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>President Donald Trump called on the U.S. Post...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>68599</th>\n      <td>Apparently, the new Kyiv government is in a hu...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68600</th>\n      <td>The USA wants to divide Syria.\\r\\n\\r\\nGreat Br...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68601</th>\n      <td>The Ukrainian coup d'etat cost the US nothing ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68602</th>\n      <td>The European Parliament falsifies history by d...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68603</th>\n      <td>A leading FSB officer, Segey Beseda, said duri...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>68604 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"df = df.sample(frac=1, random_state=42).reset_index(drop=True) # Shuffle dataset\ndf","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:26.256864Z","iopub.execute_input":"2025-06-16T07:43:26.257056Z","iopub.status.idle":"2025-06-16T07:43:26.278488Z","shell.execute_reply.started":"2025-06-16T07:43:26.257042Z","shell.execute_reply":"2025-06-16T07:43:26.277893Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                    text  label\n0      Former Russian economy minister Alexei Ulyukay...      1\n1      Republicans were just given a leg up over Demo...      0\n2      This has to be one of the best remix videos ev...      0\n3      In line with the new Language Law, Russian is ...      0\n4      JERUSALEM  —   A day after approving the const...      1\n...                                                  ...    ...\n68599  The Super Bowl had not yet begun and Trump fan...      0\n68600  U.S. House Republicans on Friday won passage o...      1\n68601  Share on Facebook Share on Twitter Known to th...      0\n68602  A New Jersey man who worked at the World Trade...      1\n68603  Turkey and Iran have agreed to discuss within ...      1\n\n[68604 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Former Russian economy minister Alexei Ulyukay...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Republicans were just given a leg up over Demo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This has to be one of the best remix videos ev...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In line with the new Language Law, Russian is ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JERUSALEM  —   A day after approving the const...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>68599</th>\n      <td>The Super Bowl had not yet begun and Trump fan...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68600</th>\n      <td>U.S. House Republicans on Friday won passage o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>68601</th>\n      <td>Share on Facebook Share on Twitter Known to th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>68602</th>\n      <td>A New Jersey man who worked at the World Trade...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>68603</th>\n      <td>Turkey and Iran have agreed to discuss within ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>68604 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"* Kiểm tra imbalance","metadata":{}},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:43:26.279131Z","iopub.execute_input":"2025-06-16T07:43:26.279356Z","iopub.status.idle":"2025-06-16T07:43:26.286614Z","shell.execute_reply.started":"2025-06-16T07:43:26.279320Z","shell.execute_reply":"2025-06-16T07:43:26.285962Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"label\n1    34526\n0    34078\nName: count, dtype: int64"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"=> Dữ liệu không bị imbalance","metadata":{}},{"cell_type":"markdown","source":"- Xử lý các văn bản không phải là tiếng Anh","metadata":{}},{"cell_type":"code","source":"# def safe_detect(x):\n#     if isinstance(x, str) and x.strip() and len(x.strip()) > 20:\n#         try:\n#             return detect(x)\n#         except LangDetectException:\n#             return 'unknown'\n#     return 'unknown'\n\n# df['lang'] = df['text'].apply(safe_detect)\n# non_english = df[df['lang'] != 'en']\n# print(non_english)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:43:26.287198Z","iopub.execute_input":"2025-06-16T07:43:26.287389Z","iopub.status.idle":"2025-06-16T07:43:26.301483Z","shell.execute_reply.started":"2025-06-16T07:43:26.287371Z","shell.execute_reply":"2025-06-16T07:43:26.300782Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# df = df.drop(columns=\"lang\", axis=1) # Xóa cột phụ sau khi xử lý","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:43:26.302121Z","iopub.execute_input":"2025-06-16T07:43:26.302380Z","iopub.status.idle":"2025-06-16T07:43:26.315391Z","shell.execute_reply.started":"2025-06-16T07:43:26.302359Z","shell.execute_reply":"2025-06-16T07:43:26.314840Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"- Xử lý các văn bản với số từ ít hơn 5","metadata":{}},{"cell_type":"code","source":"# Đếm số từ trong mỗi dòng\nshort_texts = df[df['text'].apply(lambda x: len(str(x).split()) < 5)]\n\n# In ra các dòng này\nprint(short_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:43:26.316077Z","iopub.execute_input":"2025-06-16T07:43:26.316287Z","iopub.status.idle":"2025-06-16T07:43:28.036447Z","shell.execute_reply.started":"2025-06-16T07:43:26.316273Z","shell.execute_reply":"2025-06-16T07:43:28.035757Z"}},"outputs":[{"name":"stdout","text":"                                                  text  label\n127                                 Florida for Trump!      0\n288    A MUST watch video!https://youtu.be/-5Z-jJ2Z4bU      0\n772                                               Cool      0\n965                    That would be unconstitutional.      0\n1115                   Around 120,000 displaced people      1\n...                                                ...    ...\n67547                           TRUMP VICTORY FOR SURE      0\n67689                                        Brilliant      0\n67766                                  Good guy.\\n👍👍👍👍      0\n67797      https://www.youtube.com/watch?v=gqxwF-TeYas      0\n67834                                        Horseshit      0\n\n[170 rows x 2 columns]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"short_texts[short_texts['label']==1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:43:28.037090Z","iopub.execute_input":"2025-06-16T07:43:28.037361Z","iopub.status.idle":"2025-06-16T07:43:28.044335Z","shell.execute_reply.started":"2025-06-16T07:43:28.037328Z","shell.execute_reply":"2025-06-16T07:43:28.043716Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                   text  label\n1115    Around 120,000 displaced people      1\n20229  Republican Congressman Will Hurd      1\n24713                          Ted Cruz      1\n26250                Four U.S. senators      1\n28034                          “On 1/20      1\n31892                               No.      1\n40323                         (Reuters)      1\n57596                  Jan 29 (Reuters)      1\n65117                     advertisement      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1115</th>\n      <td>Around 120,000 displaced people</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20229</th>\n      <td>Republican Congressman Will Hurd</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24713</th>\n      <td>Ted Cruz</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26250</th>\n      <td>Four U.S. senators</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28034</th>\n      <td>“On 1/20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31892</th>\n      <td>No.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>40323</th>\n      <td>(Reuters)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>57596</th>\n      <td>Jan 29 (Reuters)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65117</th>\n      <td>advertisement</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"=> Xóa các văn bản có số từ <5 vì với label 1 - true news thì thật sự không có ý nghĩa -> có thể làm model dự đoán sai.","metadata":{}},{"cell_type":"code","source":"# Loại bỏ các dòng có số từ < 5\ndf = df[df['text'].apply(lambda x: len(str(x).split()) >= 5)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:43:28.045107Z","iopub.execute_input":"2025-06-16T07:43:28.045442Z","iopub.status.idle":"2025-06-16T07:43:29.770160Z","shell.execute_reply.started":"2025-06-16T07:43:28.045424Z","shell.execute_reply":"2025-06-16T07:43:29.769569Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Clean text","metadata":{}},{"cell_type":"markdown","source":"- Làm sạch văn bản (lower, bỏ dấu câu, stopwords, stemming...) + Tokenizer","metadata":{}},{"cell_type":"code","source":"# The first running\nnltk.download('stopwords')\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:29.770881Z","iopub.execute_input":"2025-06-16T07:43:29.771097Z","iopub.status.idle":"2025-06-16T07:43:29.900164Z","shell.execute_reply.started":"2025-06-16T07:43:29.771079Z","shell.execute_reply":"2025-06-16T07:43:29.899621Z"},"trusted":true},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nstemmer = PorterStemmer()","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:29.900896Z","iopub.execute_input":"2025-06-16T07:43:29.901384Z","iopub.status.idle":"2025-06-16T07:43:29.906263Z","shell.execute_reply.started":"2025-06-16T07:43:29.901359Z","shell.execute_reply":"2025-06-16T07:43:29.905781Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def clean_text(row):\n    row = str(row).lower()\n\n    # Remove email headers\n    row = re.sub(r'(?i)\\b(from|to|cc|bcc|subject|date|return-path|message-id|thread-topic|thread-index|content-type|mime-version|boundary|received|x-[\\w-]+):.*', ' ', row)\n    \n    # Remove mailto links\n    row = re.sub(r'mailto:[^\\s]+', ' ', row)\n    \n    # Decode quoted-printable\n    row = quopri.decodestring(row.encode('utf-8')).decode('utf-8', errors='ignore')\n    \n    # Unescape HTML entities\n    row = html.unescape(row)\n    \n    # Strip HTML tags\n    if '<' in row and '>' in row:\n        row = BeautifulSoup(row, \"lxml\").get_text()\n    \n    # Normalize\n    row = re.sub(r'[\\t\\r\\n]', ' ', row)\n    row = re.sub(r'[_~+\\-]{2,}', ' ', row)\n    row = re.sub(r\"[<>()|&©ø%\\[\\]\\\\~*\\$€£¥]\", ' ', row)\n    row = re.sub(r\"\\\\x[0-9a-fA-F]{2}\", ' ', row)\n    row = re.sub(r'(https?://)([^/\\s]+)([^\\s]*)', r'\\2', row)\n    row = re.sub(r'[a-f0-9]{16,}', ' ', row)\n    row = re.sub(r'([.?!])[\\s]*\\1+', r'\\1', row)\n    row = re.sub(r'\\s+', ' ', row)\n\n    # Remove code-like keywords\n    row = re.sub(r'\\b(function|var|return|typeof|window|document|eval|\\.split)\\b', ' ', row)\n    \n    # Remove programming symbols\n    row = re.sub(r'[{}=<>\\[\\]^~|`#@*]', ' ', row)\n\n    # Remove all emoji\n    row = emoji.replace_emoji(row, replace='')\n\n    # Cut code JS minify or base36 encode\n    code_gibberish = re.search(r'[a-z0-9]{20,}', row)\n    if code_gibberish and len(row) - code_gibberish.start() > 50:\n        row = row[:code_gibberish.start()]\n\n    # Cut off JS/CDATA tail\n    cutoff = re.search(\n        r'(//\\s*!?\\s*cdata|function\\s*\\(|var\\s+[a-zA-Z]|window\\s*\\.\\s*|document\\s*\\.\\s*|this\\s*\\.)',\n        row\n    )\n    if cutoff and len(row) - cutoff.start() > 10:\n        row = row[:cutoff.start()]\n\n    row = re.sub(r'!+\\s*cdata\\s*!+', ' ', row, flags=re.IGNORECASE)\n\n    return row.strip()\n\ndf['clean_text'] = df['text'].apply(clean_text)\ndf['clean_text']","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:43:29.906913Z","iopub.execute_input":"2025-06-16T07:43:29.907083Z","iopub.status.idle":"2025-06-16T07:46:46.557229Z","shell.execute_reply.started":"2025-06-16T07:43:29.907069Z","shell.execute_reply":"2025-06-16T07:46:46.556484Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2492486288.py:56: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['clean_text'] = df['text'].apply(clean_text)\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0        former russian economy minister alexei ulyukay...\n1        republicans were just given a leg up over demo...\n2        this has to be one of the best remix videos ev...\n3        in line with the new language law, russian is ...\n4        jerusalem — a day after approving the construc...\n                               ...                        \n68599    the super bowl had not yet begun and trump fan...\n68600    u.s. house republicans on friday won passage o...\n68601    share on facebook share on twitter known to th...\n68602    a new jersey man who worked at the world trade...\n68603    turkey and iran have agreed to discuss within ...\nName: clean_text, Length: 68434, dtype: object"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"def tokenize_and_filter(text):  # dùng cho các mô hình truyền thống như TF-IDF\n    # Mở rộng các từ viết tắt (contractions)\n    text = contractions.fix(text)\n\n    # Tokenize\n    tokens = word_tokenize(text)\n\n    # Lọc stopwords và chỉ giữ từ alphabet -> stemming\n    return [stemmer.stem(w) for w in tokens if w.lower() not in stop_words and w.isalpha()]","metadata":{"execution":{"iopub.status.busy":"2025-06-16T07:46:46.560498Z","iopub.execute_input":"2025-06-16T07:46:46.560911Z","iopub.status.idle":"2025-06-16T07:46:46.564983Z","shell.execute_reply.started":"2025-06-16T07:46:46.560891Z","shell.execute_reply":"2025-06-16T07:46:46.564387Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# Model building","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Chuẩn bị dữ liệu\nX = df['clean_text']\ny = df['label']\n\n# Chia tập huấn luyện (train) và tập kiểm tra (test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# Lưu lại index gốc\nX_test_indices = X_test.index\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:46:46.565717Z","iopub.execute_input":"2025-06-16T07:46:46.565949Z","iopub.status.idle":"2025-06-16T07:47:00.376211Z","shell.execute_reply.started":"2025-06-16T07:46:46.565925Z","shell.execute_reply":"2025-06-16T07:47:00.375656Z"}},"outputs":[{"name":"stderr","text":"2025-06-16 07:46:48.179669: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750060008.409839      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750060008.485657      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Tokenization\n# Fit tokenizer trên dữ liệu train\ntokenizer = Tokenizer(num_words=5000) # giữ lại 5000 từ phổ biến nhất\ntokenizer.fit_on_texts(X_train)\n# Convert văn bản thành câu và padding\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)\nX_train_pad = pad_sequences(X_train_seq, maxlen=512, padding='post', truncating='post')\nX_test_pad = pad_sequences(X_test_seq, maxlen=512, padding='post', truncating='post')\n\n# Convert to tensor\nX_train_tensor = torch.tensor(X_train_pad, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test_pad, dtype=torch.long)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n\n# Dataset & DataLoader\nclass TextDataset(Dataset):\n    '''\n    Tạo custom Dataset từ dữ liệu đã padding và label.\n    '''\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\ntrain_dataset = TextDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_dataset = TextDataset(X_test_tensor, y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:47:00.376982Z","iopub.execute_input":"2025-06-16T07:47:00.377432Z","iopub.status.idle":"2025-06-16T07:47:38.876222Z","shell.execute_reply.started":"2025-06-16T07:47:00.377413Z","shell.execute_reply":"2025-06-16T07:47:38.875466Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## 1. Multilevel-CNN\n- Bắt được đặc trưng từ từ, cụm từ, câu bằng các kernel kích thước khác nhau (3, 4, 5,...).\n- Phù hợp với dữ liệu dài + đa dạng, không phụ thuộc vào thứ tự quá dài như RNN.\n- Huấn luyện nhanh hơn LSTM, độ chính xác cao hơn CNN đơn thuần.\n\n## 2. CNN + BiLSTM\n- CNN trích đặc trưng cục bộ, sau đó BiLSTM hiểu ngữ cảnh hai chiều (trước và sau).\n- Phù hợp cho dữ liệu có logic tuyến tính (như tin tức).\n- Độ chính xác cao, tuy chậm hơn Multilevel-CNN chút nhưng vẫn tốt nếu tối ưu đúng.","metadata":{}},{"cell_type":"markdown","source":"## Multilevel-CNN\n\n**Kiến trúc gợi ý:**\n\nInput (chuỗi văn bản)\n→ Embedding Layer\n→ Conv1D (kernel size 3) → GlobalMaxPool\n→ Conv1D (kernel size 4) → GlobalMaxPool\n→ Conv1D (kernel size 5) → GlobalMaxPool\n→ Concatenate\n→ Dense layers → Dropout\n→ Output (Sigmoid / Softmax)","metadata":{}},{"cell_type":"code","source":"# Định nghĩa model\nclass MultilevelCNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim=16, num_classes=1):\n        super(MultilevelCNN, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim) # Embedding layer\n        self.conv3 = nn.Conv1d(in_channels=embed_dim, out_channels=32, kernel_size=3)\n        self.conv4 = nn.Conv1d(in_channels=embed_dim, out_channels=32, kernel_size=4)\n        self.conv5 = nn.Conv1d(in_channels=embed_dim, out_channels=32, kernel_size=5)\n        self.dropout = nn.Dropout(0.2)\n        self.fc = nn.Linear(32*3, 10)\n        self.out = nn.Linear(10, num_classes)\n        \n    def forward(self, x):\n        x = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n        x = x.permute(0, 2, 1) # (batch_size, embed_dim, seq_len)\n\n        x1 = F.relu(self.conv3(x)) # Conv1d với kernel_size = 3\n        x2 = F.relu(self.conv4(x)) # Conv1d với kernel_size = 4\n        x3 = F.relu(self.conv5(x)) # Conv1d với kernel_size = 5\n\n        x1 = F.max_pool1d(x1, x1.size(2)).squeeze(2)\n        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n\n        x = torch.cat((x1, x2, x3), 1) # Nối lại các features\n        x = F.relu(self.fc(x))\n        x = self.dropout(x)\n        x = torch.sigmoid(self.out(x)) # Binary classification\n        return x\n\n# Model, loss, optimizer\nmodel = MultilevelCNN(vocab_size=5000).to(device)\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_val_loss = float('inf')\npatience = 2\nwait = 0\nnum_epochs = 20\n\ntrain_losses = []\nval_losses = []\nval_accuracies = []\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\", leave=True)\n    for batch_X, batch_y in loop:\n        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n        optimizer.zero_grad()\n        outputs = model(batch_X).squeeze(1)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n\n    # === Validation sau mỗi epoch ===\n    model.eval()\n    correct, val_loss_total, total = 0, 0, 0\n    val_loop = tqdm(test_loader, desc=f\"Epoch {epoch+1} [Val]\", leave=True)\n    with torch.no_grad():\n        for batch_X, batch_y in val_loop:\n            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n            outputs = model(batch_X).squeeze(-1)\n            val_loss = criterion(outputs, batch_y)\n            val_loss_total += val_loss.item()\n            \n            preds = (outputs > 0.5).float()\n            correct += (preds == batch_y).sum().item()\n            total += batch_y.size(0)\n            val_loop.set_postfix(val_loss=val_loss.item())\n\n    # Calculate average value\n    train_loss_avg = train_loss / len(test_loader)\n    val_loss_avg = val_loss_total / len(test_loader)\n    val_acc = correct / total\n\n    # Save value into list\n    train_losses.append(train_loss_avg)\n    val_losses.append(val_loss_avg)\n    val_accuracies.append(val_acc)\n\n    \n    print(f\"Epoch {epoch+1} | Train Loss: {train_loss_avg:.4f} | Val Loss: {val_loss_avg:.4f} | Val Acc: {val_acc*100:.2f}%\")\n\n    # === Early stopping check ===\n    if val_loss_avg < best_val_loss:\n        best_val_loss = val_loss_avg\n        wait = 0\n        torch.save(model.state_dict(), \"best_multilevelcnn_model.pt\")\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n# Write into csv file\nlog_df = pd.DataFrame({\n    \"epoch\": list(range(1, len(train_losses)+1)),\n    \"train_loss\": train_losses,\n    \"val_loss\": val_losses,\n    \"val_accuracy\": val_accuracies\n})\nlog_df.to_csv(\"training_multilevelcnn.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T08:11:58.835223Z","iopub.execute_input":"2025-06-16T08:11:58.835733Z"}},"outputs":[{"name":"stderr","text":"Epoch 1 [Train]: 100%|██████████| 1497/1497 [00:06<00:00, 225.26it/s, loss=0.0826]\nEpoch 1 [Val]: 100%|██████████| 642/642 [00:01<00:00, 328.91it/s, val_loss=0.243] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 0.7682 | Val Loss: 0.1836 | Val Acc: 92.84%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Train]: 100%|██████████| 1497/1497 [00:06<00:00, 227.69it/s, loss=0.206] \nEpoch 2 [Val]: 100%|██████████| 642/642 [00:01<00:00, 358.67it/s, val_loss=0.0877]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 0.4039 | Val Loss: 0.1476 | Val Acc: 94.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Train]: 100%|██████████| 1497/1497 [00:06<00:00, 228.76it/s, loss=0.081] \nEpoch 3 [Val]: 100%|██████████| 642/642 [00:01<00:00, 357.90it/s, val_loss=0.129] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 0.3068 | Val Loss: 0.1513 | Val Acc: 94.23%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 [Train]:  44%|████▎     | 652/1497 [00:03<00:04, 201.14it/s, loss=0.0507] ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Predict\ndef predict_text(texts):\n    model.eval()\n    seq = tokenizer.texts_to_sequences(texts)\n    padded = pad_sequences(seq, maxlen=512, padding='post', truncating='post')\n    tensor = torch.tensor(padded, dtype=torch.long).to(device)\n    with torch.no_grad():\n        outputs = model(tensor)\n        probs = outputs.cpu().numpy()\n        return probs, (probs > 0.5).astype(int)\n\nprobs, preds = predict_text(X_test)\n\n# Lấy lại văn bản gốc từ df['text'] theo index\nraw_texts = df.loc[X_test_indices, 'text'].tolist()\n# Tạo DataFrame kết quả\nresults_df = pd.DataFrame({\n    \"index\": X_test_indices,                     # giữ lại chỉ số gốc\n    \"text\": raw_texts,                           # văn bản\n    \"prob\": np.round(probs.flatten(), 4),        # xác suất dự đoán (real)\n    \"predict\": preds.flatten(),                  # nhãn dự đoán (0/1)\n    \"label\": y_test.tolist()                     # nhãn thật\n})\n\n# Hiển thị 20 dòng đầu\nprint(results_df.head(20))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T07:47:42.608395Z","iopub.status.idle":"2025-06-16T07:47:42.608621Z","shell.execute_reply.started":"2025-06-16T07:47:42.608507Z","shell.execute_reply":"2025-06-16T07:47:42.608525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport pandas as pd\n\n# Chuyển y_test về numpy array (nếu chưa)\ntrue_labels = y_test.values\n\n# Accuracy\nacc = accuracy_score(true_labels, preds)\nprint(f\"\\nAccuracy: {acc:.4f}\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, preds)\nconf_df = pd.DataFrame(conf_matrix)\n\nprint(\"\\nConfusion Matrix:\")\nprint(conf_df)\n\n# Classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_labels, preds))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CNN + BiLSTM\n\n**Kiến trúc gợi ý:**\n\nEmbedding → 1D Convolution (CNN) → BiLSTM (2 chiều) → LSTM hidden → Dropout → Dense → Output\n","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# Định nghĩa model\nclass CNNBiLSTM(nn.Module):\n    def __init__(self, vocab_size, embed_dim=100, hidden_dim=128):\n        super(CNNBiLSTM, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.conv = nn.Conv1d(in_channels=embed_dim, out_channels=128, kernel_size=5, padding=2)\n        self.bilstm = nn.LSTM(input_size=128, hidden_size=hidden_dim, bidirectional=True, batch_first=True)\n        self.dropout = nn.Dropout(0.2)\n        self.fc = nn.Linear(hidden_dim*2, 64)\n        self.out = nn.Linear(64, 1)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = x.permute(0, 2, 1)\n        x = F.relu(self.conv(x))\n        x = x.permute(0, 2, 1)\n        lstm_out, _ = self.bilstm(x)\n        x = lstm_out[:, -1, :]  # hidden cuối\n        x = self.dropout(F.relu(self.fc(x)))\n        x = torch.sigmoid(self.out(x)).squeeze(1)\n        return x\n\n# Model, loss, optimizer\nmodel = CNNBiLSTM(vocab_size=5000).to(device)\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nbest_val_loss = float('inf')\npatience = 2\nwait = 0\nnum_epochs = 20\n\ntrain_losses = []\nval_losses = []\nval_accuracies = []\n\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\", leave=True)\n    for batch_X, batch_y in loop:\n        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n        optimizer.zero_grad()\n        outputs = model(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * batch_X.size(0)\n        loop.set_postfix(loss=loss.item())\n\n    # === Validation sau mỗi epoch ===\n    model.eval()\n    correct, val_loss_total, total = 0, 0, 0\n    val_loop = tqdm(test_loader, desc=f\"Epoch {epoch+1} [Val]\", leave=True)\n    with torch.no_grad():\n        for batch_X, batch_y in val_loop:\n            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n            outputs = model(batch_X).squeeze(-1)\n            val_loss = criterion(outputs, batch_y)\n            val_loss_total += val_loss.item() * batch_X.size(0)\n            \n            preds = (outputs > 0.5).float()\n            correct += (preds == batch_y).sum().item()\n            total += batch_y.size(0)\n            val_loop.set_postfix(val_loss=val_loss.item())\n    \n    # Calculate average value\n    train_loss_avg = train_loss / len(test_loader.dataset)\n    val_loss_avg = val_loss_total / len(test_loader.dataset)\n    val_acc = correct / total\n\n    # Save value into list\n    train_losses.append(train_loss_avg)\n    val_losses.append(val_loss_avg)\n    val_accuracies.append(val_acc)\n    \n    print(f\"Epoch {epoch+1} | Train Loss: {train_loss_avg:.4f} | Val Loss: {val_loss_avg:.4f} | Val Acc: {val_acc*100:.2f}%\")\n\n    # === Early stopping check ===\n    if val_loss_avg < best_val_loss:\n        best_val_loss = val_loss_avg\n        wait = 0\n        torch.save(model.state_dict(), \"best_cnn_bilstm_model.pt\")\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n# Write into csv file\nlog_df = pd.DataFrame({\n    \"epoch\": list(range(1, len(train_losses)+1)),\n    \"train_loss\": train_losses,\n    \"val_loss\": val_losses,\n    \"val_accuracy\": val_accuracies\n})\nlog_df.to_csv(\"training_cnn_bilstm.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"probs, preds = predict_text(X_test)\n\n# Lấy lại văn bản gốc từ df['text'] theo index\nraw_texts = df.loc[X_test_indices, 'text'].tolist()\n# Tạo DataFrame kết quả\nresults_df = pd.DataFrame({\n    \"index\": X_test_indices,                     # giữ lại chỉ số gốc\n    \"text\": raw_texts,                           # văn bản\n    \"prob\": np.round(probs.flatten(), 4),        # xác suất dự đoán (real)\n    \"predict\": preds.flatten(),                  # nhãn dự đoán (0/1)\n    \"label\": y_test.tolist()                     # nhãn thật\n})\n\n# Hiển thị 20 dòng đầu\nprint(results_df.head(20))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Chuyển y_test về numpy array (nếu chưa)\ntrue_labels = y_test.values\n\n# Accuracy\nacc = accuracy_score(true_labels, preds)\nprint(f\"\\nAccuracy: {acc:.4f}\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, preds)\nconf_df = pd.DataFrame(conf_matrix)\n\nprint(\"\\nConfusion Matrix:\")\nprint(conf_df)\n\n# Classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_labels, preds))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}