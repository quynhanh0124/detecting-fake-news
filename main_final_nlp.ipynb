{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nW7Xan1n6VtR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Project**\n",
        "\n",
        "## **Problem stament :**     \n",
        "\n",
        "The widespread dissemination of fake news and propaganda presents serious societal risks, including the erosion of public trust, political polarization, manipulation of elections, and the spread of harmful misinformation during crises such as pandemics or conflicts. From an NLP perspective, detecting fake news is fraught with challenges. Linguistically, fake news often mimics the tone and structure of legitimate journalism, making it difficult to distinguish using surface-level features. The absence of reliable and up-to-date labeled datasets, especially across multiple languages and regions, hampers the effectiveness of supervised learning models. Additionally, the dynamic and adversarial nature of misinformation means that malicious actors constantly evolve their language and strategies to bypass detection systems. Cultural context, sarcasm, satire, and implicit bias further complicate automated analysis. Moreover, NLP models risk amplifying biases present in training data, leading to unfair classifications and potential censorship of legitimate content. These challenges underscore the need for cautious, context-aware approaches, as the failure to address them can inadvertently contribute to misinformation, rather than mitigate it.\n",
        "\n",
        "\n",
        "\n",
        "Use datasets in link : https://drive.google.com/drive/folders/1mrX3vPKhEzxG96OCPpCeh9F8m_QKCM4z?usp=sharing\n",
        "to complete requirement.\n",
        "\n",
        "## **About dataset:**\n",
        "\n",
        "* **True Articles**:\n",
        "\n",
        "  * **File**: `MisinfoSuperset_TRUE.csv`\n",
        "  * **Sources**:\n",
        "\n",
        "    * Reputable media outlets like **Reuters**, **The New York Times**, **The Washington Post**, etc.\n",
        "\n",
        "* **Fake/Misinformation/Propaganda Articles**:\n",
        "\n",
        "  * **File**: `MisinfoSuperset_FAKE.csv`\n",
        "  * **Sources**:\n",
        "\n",
        "    * **American right-wing extremist websites** (e.g., Redflag Newsdesk, Breitbart, Truth Broadcast Network)\n",
        "    * **Public dataset** from:\n",
        "\n",
        "      * Ahmed, H., Traore, I., & Saad, S. (2017): \"Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques\" *(Springer LNCS 10618)*\n",
        "\n",
        "\n",
        "\n",
        "## **Requirement**\n",
        "\n",
        "A team consisting of three members must complete a project that involves applying the methods learned from the beginning of the course up to the present. The team is expected to follow and document the entire machine learning workflow, which includes the following steps:\n",
        "\n",
        "1. **Data Preprocessing**: Clean and prepare the dataset,etc.\n",
        "\n",
        "2. **Exploratory Data Analysis (EDA)**: Explore and visualize the data.\n",
        "\n",
        "3. **Model Building**: Select and build one or more machine learning models suitable for the problem at hand.\n",
        "\n",
        "4. **Hyperparameter set up**: Set and adjust the model's hyperparameters using appropriate methods to improve performance.\n",
        "\n",
        "5. **Model Training**: Train the model(s) on the training dataset.\n",
        "\n",
        "6. **Performance Evaluation**: Evaluate the trained model(s) using appropriate metrics (e.g., accuracy, precision, recall, F1-score, confusion matrix, etc.) and validate their performance on unseen data.\n",
        "\n",
        "7. **Conclusion**: Summarize the results, discuss the model's strengths and weaknesses, and suggest possible improvements or future work.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AJSvJwS24wn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read dataset"
      ],
      "metadata": {
        "id": "MZlAJs4n4yfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sag__UElw91_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0889c16-7acc-42c1-9324-bc1b945c4284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "KA7vmonq423g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883fb31b-4191-4173-e30e-21853d72c5cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/981.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=f0e28ffa38b8c778c7251ccad9bab8c36a2389c04a4924270801b3465a376073\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_8TpEQRINOi",
        "outputId": "1979769d-be9b-4817-ab95-34e2fc1e1b52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import library"
      ],
      "metadata": {
        "id": "ILypBVMaQLUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import html\n",
        "import os\n",
        "import quopri\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "import emoji\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from langdetect import detect, LangDetectException\n",
        "from tqdm import tqdm\n",
        "\n",
        "import contractions\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    XLNetForSequenceClassification,\n",
        "    get_scheduler,\n",
        ")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    auc,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "qmsu51HB45Iz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_df = pd.read_csv(\"/kaggle/input/misinfo/DataSet_Misinfo_TRUE.csv\")\n",
        "true_df"
      ],
      "metadata": {
        "id": "7PyECqZ-46fx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "1247cdfe-f834-4738-eaa4-f52c5f001478"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/misinfo/DataSet_Misinfo_TRUE.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-770038435>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrue_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/misinfo/DataSet_Misinfo_TRUE.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrue_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/misinfo/DataSet_Misinfo_TRUE.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df = pd.read_csv(\"/kaggle/input/misinfo/DataSet_Misinfo_FAKE.csv\")\n",
        "fake_df"
      ],
      "metadata": {
        "id": "FdFf6oSg475X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete order column\n",
        "true_df = true_df.drop('Unnamed: 0', axis=1)\n",
        "fake_df = fake_df.drop('Unnamed: 0', axis=1)"
      ],
      "metadata": {
        "id": "XqMBo7ly4-bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df.info()"
      ],
      "metadata": {
        "id": "orKgADru4_8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_df.describe()"
      ],
      "metadata": {
        "id": "9B71gKh45BQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df.describe()"
      ],
      "metadata": {
        "id": "Oyr1ehMs5Cj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "UedEPJBX5FEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Xử lý giá trị null"
      ],
      "metadata": {
        "id": "ke2XC07Z5GkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_df.isnull().sum()"
      ],
      "metadata": {
        "id": "TzZQEtPk5Lku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df.isnull().sum()"
      ],
      "metadata": {
        "id": "q8BC8NCR5M3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_df = true_df.dropna()"
      ],
      "metadata": {
        "id": "njIAkAPN5NTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Xử lý giá trị duplicate"
      ],
      "metadata": {
        "id": "z2cz30lw5K4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "Q_8t6Blo5QBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "kSaZ_iud5R7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_df = true_df.drop_duplicates()\n",
        "fake_df = fake_df.drop_duplicates()"
      ],
      "metadata": {
        "id": "JNqDdvw55TSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Thêm label và gộp 2 tập dữ liệu"
      ],
      "metadata": {
        "id": "dpvYPH0eJm89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_df['label'] = 1\n",
        "fake_df['label'] = 0\n",
        "\n",
        "df = pd.concat([true_df, fake_df], ignore_index=True)\n",
        "df"
      ],
      "metadata": {
        "id": "C6tDHB6eJnYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True) # Shuffle dataset\n",
        "df"
      ],
      "metadata": {
        "id": "928LxVh0Jo4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Kiểm tra imbalance"
      ],
      "metadata": {
        "id": "rb4Hormg5aWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "tvMmWtg25b-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Dữ liệu không bị imbalance"
      ],
      "metadata": {
        "id": "403QUP4q5e6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Xử lý các văn bản không phải là tiếng Anh"
      ],
      "metadata": {
        "id": "_vYaFeDU5kO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_detect(x):\n",
        "    if isinstance(x, str) and x.strip() and len(x.strip()) > 20:\n",
        "        try:\n",
        "            return detect(x)\n",
        "        except LangDetectException:\n",
        "            return 'unknown'\n",
        "    return 'unknown'\n",
        "\n",
        "df['lang'] = df['text'].apply(safe_detect)\n",
        "non_english = df[df['lang'] != 'en']\n",
        "print(non_english)"
      ],
      "metadata": {
        "id": "v7gyy9NYOr_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=\"lang\", axis=1) # Xóa cột phụ sau khi xử lý"
      ],
      "metadata": {
        "id": "BC_W0QPzOxVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Không xóa các dòng văn bản không phải tiếng Anh vì label 0 - fake news chiếm đa số"
      ],
      "metadata": {
        "id": "-m74wad8O_sX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Xử lý các văn bản với số từ ít hơn 5"
      ],
      "metadata": {
        "id": "IR7Z3W7_5srF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Đếm số từ trong mỗi dòng\n",
        "short_texts = df[df['text'].apply(lambda x: len(str(x).split()) < 5)]\n",
        "\n",
        "# In ra các dòng này\n",
        "print(short_texts)"
      ],
      "metadata": {
        "id": "qEqtwUXC5uJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "short_texts[short_texts['label']==1]"
      ],
      "metadata": {
        "id": "bfxfwHQP5v6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Vì các dòng có text dưới 5 kí tự không mang nhiều ý nghĩa nên loại bỏ"
      ],
      "metadata": {
        "id": "tnSviFeV5y5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loại bỏ các dòng có số từ < 5\n",
        "df = df[df['text'].apply(lambda x: len(str(x).split()) >= 5)]"
      ],
      "metadata": {
        "id": "A5p6Ku4H5xvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean text"
      ],
      "metadata": {
        "id": "4yBEgaak51Rj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Làm sạch văn bản (lower, bỏ dấu câu, stopwords, stemming...) + Tokenizer"
      ],
      "metadata": {
        "id": "kd9m-Xae52wF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The first running\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "BqU7Oo2I54mM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "ykzDhSM057Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(row):\n",
        "    row = str(row).lower()\n",
        "\n",
        "    # Remove email headers\n",
        "    row = re.sub(r'(?i)\\b(from|to|cc|bcc|subject|date|return-path|message-id|thread-topic|thread-index|content-type|mime-version|boundary|received|x-[\\w-]+):.*', ' ', row)\n",
        "\n",
        "    # Remove mailto links\n",
        "    row = re.sub(r'mailto:[^\\s]+', ' ', row)\n",
        "\n",
        "    # Decode quoted-printable\n",
        "    row = quopri.decodestring(row.encode('utf-8')).decode('utf-8', errors='ignore')\n",
        "\n",
        "    # Unescape HTML entities\n",
        "    row = html.unescape(row)\n",
        "\n",
        "    # Strip HTML tags\n",
        "    if '<' in row and '>' in row:\n",
        "        row = BeautifulSoup(row, \"lxml\").get_text()\n",
        "\n",
        "    # Normalize\n",
        "    row = re.sub(r'[\\t\\r\\n]', ' ', row)\n",
        "    row = re.sub(r'[_~+\\-]{2,}', ' ', row)\n",
        "    row = re.sub(r\"[<>()|&©ø%\\[\\]\\\\~*\\$€£¥]\", ' ', row)\n",
        "    row = re.sub(r\"\\\\x[0-9a-fA-F]{2}\", ' ', row)\n",
        "    row = re.sub(r'(https?://)([^/\\s]+)([^\\s]*)', r'\\2', row)\n",
        "    row = re.sub(r'[a-f0-9]{16,}', ' ', row)\n",
        "    row = re.sub(r'([.?!])[\\s]*\\1+', r'\\1', row)\n",
        "    row = re.sub(r'\\s+', ' ', row)\n",
        "\n",
        "    # Remove code-like keywords\n",
        "    row = re.sub(r'\\b(function|var|return|typeof|window|document|eval|\\.split)\\b', ' ', row)\n",
        "\n",
        "    # Remove programming symbols\n",
        "    row = re.sub(r'[{}=<>\\[\\]^~|`#@*]', ' ', row)\n",
        "\n",
        "    # Remove all emoji\n",
        "    row = emoji.replace_emoji(row, replace='')\n",
        "\n",
        "    # Cut code JS minify or base36 encode\n",
        "    code_gibberish = re.search(r'[a-z0-9]{20,}', row)\n",
        "    if code_gibberish and len(row) - code_gibberish.start() > 50:\n",
        "        row = row[:code_gibberish.start()]\n",
        "\n",
        "    # Cut off JS/CDATA tail\n",
        "    cutoff = re.search(\n",
        "        r'(//\\s*!?\\s*cdata|function\\s*\\(|var\\s+[a-zA-Z]|window\\s*\\.\\s*|document\\s*\\.\\s*|this\\s*\\.)',\n",
        "        row\n",
        "    )\n",
        "    if cutoff and len(row) - cutoff.start() > 10:\n",
        "        row = row[:cutoff.start()]\n",
        "\n",
        "    row = re.sub(r'!+\\s*cdata\\s*!+', ' ', row, flags=re.IGNORECASE)\n",
        "\n",
        "    return row.strip()\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "df['clean_text']"
      ],
      "metadata": {
        "id": "K0AWDT2g58rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "nW7Xan1n6VtR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Analysis"
      ],
      "metadata": {
        "id": "4xGnctfh_NtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_label_distribution(df, label_col):\n",
        "    ax = sns.countplot(x=label_col, data=df, hue=label_col, palette='pastel', dodge=False)\n",
        "\n",
        "    counts = df[label_col].value_counts().sort_index()\n",
        "    for x, y in enumerate(counts.values):\n",
        "        ax.text(x, y, f'{y}', ha='center', va='bottom', fontsize=11)\n",
        "\n",
        "    plt.legend(title='Label', labels=df[label_col].unique(),)\n",
        "    plt.title('Label Distribution')\n",
        "    plt.xlabel('Label')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n",
        "\n",
        "plot_label_distribution(df, 'label')"
      ],
      "metadata": {
        "id": "fL2B5McW6Xyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sự chênh lệch giữa hai nhãn là rất nhỏ (chỉ 448 mẫu), cho thấy tập dữ liệu khá cân bằng giữa hai lớp."
      ],
      "metadata": {
        "id": "SXhTsZeJ_R8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribution Analysis"
      ],
      "metadata": {
        "id": "cLOPAw1V_Sqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['word_count'] = df['clean_text'].apply(lambda x: len(x.split()))\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df, x='word_count', hue='label', multiple='dodge', bins=20)\n",
        "plt.title('Distribution of Word Count in True vs Fake News')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vXjwkukP_T7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đa số các bài viết (khoảng 30000 bài) có số từ từ 0 đến 5000, cho cả True News và Fake News, với nhãn 0 (True News) có phần vượt trội hơn. Rất ít bài viết có số từ vượt quá 10000, cho thấy phân bố tập trung chủ yếu ở các bài viết ngắn đến trung bình."
      ],
      "metadata": {
        "id": "zEyoJfqw_WSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['char_count'] = df['clean_text'].apply(lambda x: len(x))\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df, x='char_count', hue='label', multiple='dodge', bins=20)\n",
        "plt.title('Distribution of Character Count in True vs Fake News')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2BwaYi_K_X-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phần lớn các bài viết (khoảng 30000 bài) có số ký tự từ 0 đến 20000, với nhãn 0 (True News) chiếm ưu thế. Số lượng giảm mạnh sau 20000 ký tự, thể hiện sự tập trung ở các bài viết có số ký tự thấp đến trung bình."
      ],
      "metadata": {
        "id": "kwFLXrMf_Zp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Frequency Analysis"
      ],
      "metadata": {
        "id": "Fj5Df8jG_cT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_words = ' '.join(df[df['label'] == 1]['clean_text']).split()\n",
        "true_words = set(true_words)\n",
        "\n",
        "fake_words = ' '.join(df[df['label'] == 0]['clean_text']).split()\n",
        "fake_words = set(fake_words)\n",
        "\n",
        "common_words = true_words.intersection(fake_words)\n",
        "\n",
        "unique_true_words = true_words - common_words\n",
        "unique_fake_words = fake_words - common_words\n",
        "\n",
        "print(f\"Number of common words between true and fake news: {len(common_words)}\")\n",
        "print(f\"Number of unique words in true news: {len(unique_true_words)}\")\n",
        "print(f\"Number of unique words in fake news: {len(unique_fake_words)}\")"
      ],
      "metadata": {
        "id": "U0iBB2-T_bYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_word_freq = Counter(true_words)\n",
        "most_common_true = true_word_freq.most_common(20)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=[word[1] for word in most_common_true], y=[word[0] for word in most_common_true])\n",
        "plt.title('Top 20 Most Common Words in True News')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Words')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XCRIrsUa_fHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_word_freq = Counter(fake_words)\n",
        "most_common_fake = fake_word_freq.most_common(20)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=[word[1] for word in most_common_fake], y=[word[0] for word in most_common_fake])\n",
        "plt.title('Top 20 Most Common Words in Fake News')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Words')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qF3RZjSp_gxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cả hai đồ thị \"Top 20 Most Common Words in True News\" và \"Top 20 Most Common Words in Fake News\" đều thể hiện tần suất xuất hiện của các từ phổ biến nhất trong từng loại tin tức. Từ `the` dẫn đầu với tần suất cao nhất trong cả hai trường hợp, tiếp theo là `to`, `of`, và `and`, cho thấy đây là các từ chức năng phổ biến. True News có tần suất tối đa khoảng 1 triệu, trong khi Fake News có tần suất cao hơn đáng kể, lên đến gần 8 triệu, phản ánh mật độ từ cao hơn trong Fake News."
      ],
      "metadata": {
        "id": "kAkLl7OI_ibc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_word_freq = Counter(common_words)\n",
        "most_common_shared = common_word_freq.most_common(20)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=[word[1] for word in most_common_shared], y=[word[0] for word in most_common_shared])\n",
        "plt.title('Top 20 Most Common Words Shared Between True and Fake News')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Words')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pXBuVyLV_kKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(true_words))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(true_wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud for True News')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aqVGKXVf_mUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(fake_words))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(fake_wordcloud, interpolation='bilinear')\n",
        "plt.title('Word Cloud for Fake News')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HDWpfCgv_n9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cả hai đều có sự xuất hiện của `trump` và `clinton` với kích thước lớn, nhưng Fake News có thêm các từ liên quan đến phương tiện truyền thông (như `twitter`, `youtube`, `video`) và từ cảm xúc (như `good`, `attack`), gợi ý sự khác biệt về phong cách và nội dung so với True News chỉ tập trung vào các thuật ngữ chính trị và hành chính."
      ],
      "metadata": {
        "id": "H15ZgvzC_qNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## n-grams"
      ],
      "metadata": {
        "id": "7G57yoDC_s1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n_grams(corpus, ngram_range=(2, 2), n=None):\n",
        "    vec = CountVectorizer(ngram_range=ngram_range, stop_words='english').fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "metadata": {
        "id": "_w0VeIAS_uSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_positive_unigrams = get_top_n_grams(df[df['label'] == 1]['clean_text'], ngram_range=(1, 1), n=20)\n",
        "top_negative_unigrams = get_top_n_grams(df[df['label'] == 0]['clean_text'], ngram_range=(1, 1), n=20)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=[word[1] for word in top_positive_unigrams], y=[word[0] for word in top_positive_unigrams])\n",
        "plt.title('Top 20 Unigrams in True News')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Unigrams')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=[word[1] for word in top_negative_unigrams], y=[word[0] for word in top_negative_unigrams])\n",
        "plt.title('Top 20 Unigrams in Fake News')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Unigrams')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DcrPAUB0_vVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trong True News, `said` dẫn đầu với tần suất cao nhất (gần 160,000), theo sau là `trump`, `mr`, `president`, và `new`, cho thấy sự tập trung vào phát ngôn và các nhân vật chính trị. Trong Fake News, `trump` đứng đầu với tần suất vượt trội (gần 80,000), tiếp theo là `people`, `said`, `clinton` và `president`, phản ánh sự chú trọng vào các nhân vật chính trị và công chúng.\n",
        "\n",
        "True News có tần suất tổng thể cao hơn (lên đến 160,000), trong khi Fake News có phạm vi tần suất thấp hơn (tối đa 80,000), nhưng danh sách từ đa dạng hơn với các thuật ngữ như `election` và `world`."
      ],
      "metadata": {
        "id": "tzrBzmNh_yRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_positive_bigrams = get_top_n_grams(df[df['label'] == 1]['clean_text'], ngram_range=(2, 2), n=20)\n",
        "top_negative_bigrams = get_top_n_grams(df[df['label'] == 0]['clean_text'], ngram_range=(2, 2), n=20)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=[word[1] for word in top_positive_bigrams], y=[word[0] for word in top_positive_bigrams])\n",
        "plt.title('Top 20 Bigrams in True News')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Bigrams')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=[word[1] for word in top_negative_bigrams], y=[word[0] for word in top_negative_bigrams])\n",
        "plt.title('Top 20 Bigrams in Fake News')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Bigrams')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "umXnbIqZ_xaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cả hai đều có sự xuất hiện mạnh của `trump`, `clinton`, và `united states`, nhưng True News tập trung hơn vào các thuật ngữ chính thức (như `prime minister`, `supreme court`) với tần suất giảm đều, trong khi Fake News có thêm các từ liên quan đến truyền thông (như `twitter com`, `pic twitter`) và hình ảnh (như `featured image`, `getty images`), cho thấy sự khác biệt về phong cách và nguồn thông tin."
      ],
      "metadata": {
        "id": "pwTCEjKL_1ym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "2M7q-XXi_4Ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true_reviews = df[df['label'] == 1]['clean_text']\n",
        "tfidf_vectorizer_true = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "tfidf_true = tfidf_vectorizer_true.fit_transform(true_reviews)\n",
        "true_top_words = pd.DataFrame(tfidf_true.toarray(), columns=tfidf_vectorizer_true.get_feature_names_out()).mean().sort_values(ascending=False)[:20]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=true_top_words.values, y=true_top_words.index)\n",
        "plt.title('Top 20 TF-IDF Words in True News')\n",
        "plt.xlabel('TF-IDF Score')\n",
        "plt.ylabel('Words')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vRxlXoUx_6OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_reviews = df[df['label'] == 0]['clean_text']\n",
        "tfidf_vectorizer_fake = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "tfidf_fake = tfidf_vectorizer_fake.fit_transform(fake_reviews)\n",
        "fake_top_words = pd.DataFrame(tfidf_fake.toarray(), columns=tfidf_vectorizer_fake.get_feature_names_out()).mean().sort_values(ascending=False)[:20]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=fake_top_words.values, y=fake_top_words.index)\n",
        "plt.title('Top 20 TF-IDF Words in Fake News')\n",
        "plt.xlabel('TF-IDF Score')\n",
        "plt.ylabel('Words')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GJPaMzj5_7vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cả hai đều có sự xuất hiện mạnh của `trump`, `clinton`, `president`, và `said`, nhưng True News nhấn mạnh các thuật ngữ hành chính (như `government`, `states`) với điểm TF-IDF giảm đều, trong khi Fake News nổi bật với các từ như `hillary`, `obama`, và `russia`, gợi ý sự tập trung vào các cá nhân và sự kiện cụ thể."
      ],
      "metadata": {
        "id": "CiCvHjEM_-Vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Textual Feature Distribution Analysis"
      ],
      "metadata": {
        "id": "rGIhetpC_-3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_polarity(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "df['polarity'] = df['clean_text'].apply(get_polarity)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df, x='polarity', hue='label', multiple='stack', bins=50, kde=True)\n",
        "plt.title('Polarity Distribution by Label')\n",
        "plt.xlabel('Polarity')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GYT4cNW0_9l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân phối của cả hai nhãn (0 và 1) tập trung chủ yếu quanh giá trị Polarity gần 0, rất ít bài viết với Polarity cực đoan (dưới -0.75 hoặc trên 0.75) cho thấy phần lớn các bài viết có độ tích cực hoặc tiêu cực trung bình. Nhãn 0 (Fake News) có số lượng bài viết cao hơn đáng kể so với nhãn 1 (True News)."
      ],
      "metadata": {
        "id": "EE9sDhFnAB4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subjectivity(text):\n",
        "    return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "df['subjectivity'] = df['clean_text'].apply(get_subjectivity)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df, x='subjectivity', hue='label', multiple='stack', bins=50, kde=True)\n",
        "plt.title('Subjectivity Distribution by Label')\n",
        "plt.xlabel('Subjectivity')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B9u6x4BsAEGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân phối của cả hai nhãn (0 và 1) tập trung chủ yếu ở giá trị Subjectivity từ 0 đến 0.6, rất ít bài viết lớn hơn 0.6. Nhãn 0 (Fake News) chiếm ưu thế tổng thể và có số lượng bài viết cao vượt trội hơn nhãn 1 ở giá trị 0.1 với khoảng 3.000 bài viết."
      ],
      "metadata": {
        "id": "i1jZ5dMoAG47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_flesch_kincaid(text):\n",
        "    return textstat.flesch_kincaid_grade(text)\n",
        "\n",
        "df['readability_score'] = df['clean_text'].apply(get_flesch_kincaid)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df, x='readability_score', hue='label', multiple='stack', bins=50, kde=True)\n",
        "plt.title('Readability Score Distribution for True vs Fake News')\n",
        "plt.xlabel('Flesch-Kincaid Grade Level')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.legend(labels=['Fake', 'True'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QzshoVNnAIbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân phối của cả tin thật (nhãn 1) và tin giả (nhãn 0) tập trung chủ yếu ở mức Flesch-Kincaid Grade Level từ 0 đến 40, cả hai loại tin đều có số lượng giảm mạnh khi Flesch-Kincaid Grade Level tăng trên 40, với rất ít bài viết ở mức trên 80, cho thấy cả hai loại đều có mức độ dễ đọc."
      ],
      "metadata": {
        "id": "8RAvmdnLAJ4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus"
      ],
      "metadata": {
        "id": "SbhelCr9ANNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_punctuation(text, punct):\n",
        "    return text.count(punct)\n",
        "\n",
        "df['exclamation_count'] = df['clean_text'].apply(lambda x: count_punctuation(x, '!'))\n",
        "df['question_count'] = df['clean_text'].apply(lambda x: count_punctuation(x, '?'))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df, x='exclamation_count', hue='label', multiple='stack', bins=30)\n",
        "plt.title('Exclamation Mark (!) Distribution by Label')\n",
        "plt.xlabel('Number of Exclamation Marks')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df, x='question_count', hue='label', multiple='stack', bins=30)\n",
        "plt.title('Question Mark (?) Distribution by Label')\n",
        "plt.xlabel('Number of Question Marks')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yq5lUCYvAOTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['text', 'label', 'clean_text']]"
      ],
      "metadata": {
        "id": "Ri4YRqhkARYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model building"
      ],
      "metadata": {
        "id": "K5FEHQyZ6BbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set parameters"
      ],
      "metadata": {
        "id": "fWZ2HCyWR6zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 42\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "1dMwo7LNR-jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-test split"
      ],
      "metadata": {
        "id": "PmUqkSlh6DBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['clean_text'].tolist()\n",
        "y = df['label'].tolist()"
      ],
      "metadata": {
        "id": "qaMNYg9OSBex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=df['label'])\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp)"
      ],
      "metadata": {
        "id": "utsC--UE6iWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Đếm số lượng nhãn"
      ],
      "metadata": {
        "id": "Cg7wwEteKlXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train label distribution:\", Counter(y_train))\n",
        "print(\"Validation label distribution:\", Counter(y_val))\n",
        "print(\"Test label distribution:\", Counter(y_test))"
      ],
      "metadata": {
        "id": "YZbh0IWl6v7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The necessary functions"
      ],
      "metadata": {
        "id": "EZMw5cAh7AJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_true, y_pred):\n",
        "  label_description = {\"0\": \"Fake News\", \"1\": \"True News\"}\n",
        "  print(\"Classification report: \\n\", classification_report(y_true , y_pred))\n",
        "\n",
        "  print(\"Confusion matrix: \\n\")\n",
        "  conf_matrix = confusion_matrix(y_true , y_pred)\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=list(label_description.values()), yticklabels=list(label_description.values()))\n",
        "  plt.xlabel('Predicted Class')\n",
        "  plt.ylabel('True Class')\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "bgdhow5h7q4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_curves(train_loss, val_loss, val_acc, title=\"Learning Curve\"):\n",
        "    epochs = range(1, len(train_loss) + 1)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    # Loss\n",
        "    axes[0].plot(epochs, train_loss, label=\"Train loss\")\n",
        "    axes[0].plot(epochs, val_loss,   label=\"Val loss\")\n",
        "    axes[0].set_xlabel(\"Epoch\"); axes[0].set_ylabel(\"Loss\")\n",
        "    axes[0].set_title(\"Loss\"); axes[0].legend(); axes[0].grid(ls=\"--\", alpha=.4)\n",
        "\n",
        "    # Val accuracy\n",
        "    axes[1].plot(epochs, val_acc, label=\"Val acc\", color=\"tab:orange\")\n",
        "    axes[1].set_xlabel(\"Epoch\"); axes[1].set_ylabel(\"Accuracy\")\n",
        "    axes[1].set_title(\"Validation accuracy\")\n",
        "    axes[1].legend(); axes[1].grid(ls=\"--\", alpha=.4)\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8aXKjXOxT37m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_curve(y_true, y_score, pos_label=1, title=\"ROC Curve\"):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=pos_label)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "    ax.plot(fpr, tpr, color=\"tab:red\",\n",
        "            label=f\"User model (AUC = {roc_auc:.2f})\", lw=2)\n",
        "\n",
        "    # random\n",
        "    ax.plot([0, 1], [0, 1], \"k--\", lw=2)  # Đường chéo\n",
        "\n",
        "    # perfect\n",
        "    ax.plot([0, 0, 1], [0, 1, 1], color=\"green\",\n",
        "            label=\"Perfect model\", lw=1)\n",
        "\n",
        "    ax.set_xlim([0.0, 1.0]); ax.set_ylim([0.0, 1.02])\n",
        "    ax.set_xlabel(\"False Positive Rate\")\n",
        "    ax.set_ylabel(\"True Positive Rate\")\n",
        "    ax.set_title(title)\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    ax.grid(alpha=0.3, ls=\"--\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return ax"
      ],
      "metadata": {
        "id": "DL_sea3IK2Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model"
      ],
      "metadata": {
        "id": "TqMoPAZm6zHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model ML"
      ],
      "metadata": {
        "id": "UZW9yBpQ629U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer    = PorterStemmer()\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "Bji6tbYjRwH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_filter(text):\n",
        "    text = contractions.fix(text)\n",
        "    tokens = word_tokenize(text)\n",
        "    return [stemmer.stem(w)\n",
        "            for w in tokens\n",
        "            if w.lower() not in stop_words\n",
        "            and w.isalpha()]"
      ],
      "metadata": {
        "id": "80nLEAP-R2Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ml_model(X, y):\n",
        "    model = Pipeline([\n",
        "        (\"tfidf\", TfidfVectorizer(\n",
        "            tokenizer=tokenize_and_filter,\n",
        "            lowercase=False,\n",
        "            preprocessor=None,\n",
        "            token_pattern=None,\n",
        "            ngram_range=(1, 2)\n",
        "        )),\n",
        "        (\"svc\", SVC(kernel='linear'))\n",
        "    ])\n",
        "\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "PWun664OC7Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_ml_model(X_train, y_train)\n",
        "\n",
        "pred = model.predict(X_val)\n",
        "evaluate(y_val, pred)"
      ],
      "metadata": {
        "id": "x53pgZBdwTlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    \"tfidf__ngram_range\": [(1, 1), (1, 2)],\n",
        "    \"tfidf__min_df\":      [2, 5, 10],\n",
        "    \"tfidf__max_df\":      [0.85, 0.9, 0.95],\n",
        "    \"tfidf__max_features\": [None, 50_000, 100_000],\n",
        "\n",
        "    \"svc__C\":            [0.1, 1, 2, 5],\n",
        "    \"svc__class_weight\": [None, \"balanced\"],\n",
        "}\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(\n",
        "        tokenizer      = tokenize_and_filter,\n",
        "        lowercase      = False,   # ta đã xử lý trong tokenizer\n",
        "        preprocessor   = None,\n",
        "        token_pattern  = None     # tắt regex mặc định\n",
        "    )),\n",
        "    (\"svc\",  SVC(kernel=\"linear\", random_state=RANDOM_STATE))\n",
        "])\n",
        "\n",
        "# Set up GridSearchCV\n",
        "gridsearch = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"f1\", verbose=1)\n",
        "\n",
        "# Find the best hyperparameters\n",
        "gridsearch.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found and the best cross-validation score\n",
        "print(\"Best Parameters:\", gridsearch.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", gridsearch.best_score_)\n",
        "\n",
        "# Save the fitted GridSearchCV object to a pkl file\n",
        "with open('best_svm.pkl', 'wb') as file:\n",
        "    pickle.dump(gridsearch, file)"
      ],
      "metadata": {
        "id": "TKdI9Y_YREpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GridSearchCV object from the pickle file\n",
        "with open('best_svm.pkl', 'rb') as file:\n",
        "    loaded_gridsearch = pickle.load(file)\n",
        "\n",
        "print(\"Best Parameters:\", loaded_gridsearch.best_params_)\n",
        "\n",
        "best_model = loaded_gridsearch.best_estimator_\n",
        "\n",
        "y_score = best_model.decision_function(X_test)"
      ],
      "metadata": {
        "id": "1wsUy2RHU7va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model DL cơ bản"
      ],
      "metadata": {
        "id": "uWnMVxSh74a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Multilevel-CNN\n",
        "- Bắt được đặc trưng từ từ, cụm từ, câu bằng các kernel kích thước khác nhau (3, 4, 5,...).\n",
        "- Phù hợp với dữ liệu dài + đa dạng, không phụ thuộc vào thứ tự quá dài như RNN.\n",
        "- Huấn luyện nhanh hơn LSTM, độ chính xác cao hơn CNN đơn thuần.\n",
        "\n",
        "#### 2. CNN + BiLSTM\n",
        "- CNN trích đặc trưng cục bộ, sau đó BiLSTM hiểu ngữ cảnh hai chiều (trước và sau).\n",
        "- Phù hợp cho dữ liệu có logic tuyến tính (như tin tức).\n",
        "- Độ chính xác cao, tuy chậm hơn Multilevel-CNN chút nhưng vẫn tốt nếu tối ưu đúng."
      ],
      "metadata": {
        "id": "vtwE6NRH8mJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multilevel-CNN\n",
        "\n",
        "**Kiến trúc gợi ý:**\n",
        "\n",
        "Input (chuỗi văn bản)\n",
        "→ Embedding Layer\n",
        "→ Conv1D (kernel size 3) → GlobalMaxPool\n",
        "→ Conv1D (kernel size 4) → GlobalMaxPool\n",
        "→ Conv1D (kernel size 5) → GlobalMaxPool\n",
        "→ Concatenate\n",
        "→ Dense layers → Dropout (chưa có trong code)\n",
        "→ Output (Sigmoid / Softmax)"
      ],
      "metadata": {
        "id": "jWDeUpSR8oJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "# Fit tokenizer trên dữ liệu train\n",
        "tokenizer = Tokenizer(num_words=5000) # giữ lại 5000 từ phổ biến nhất\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "# Convert văn bản thành câu và padding\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=512, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=512, padding='post', truncating='post')\n",
        "\n",
        "# Convert to tensor\n",
        "X_train_tensor = torch.tensor(X_train_pad, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test_pad, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "# Dataset & DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    '''\n",
        "    Tạo custom Dataset từ dữ liệu đã padding và label.\n",
        "    '''\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = TextDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataset = TextDataset(X_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Định nghĩa model\n",
        "class MultilevelCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes=1):\n",
        "        super(MultilevelCNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim) # Embedding layer\n",
        "        self.conv3 = nn.Conv1d(in_channels=embed_dim, out_channels=32, kernel_size=3)\n",
        "        self.conv4 = nn.Conv1d(in_channels=embed_dim, out_channels=32, kernel_size=4)\n",
        "        self.conv5 = nn.Conv1d(in_channels=embed_dim, out_channels=32, kernel_size=5)\n",
        "        self.fc = nn.Linear(32*3, 10)\n",
        "        self.out = nn.Linear(10, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
        "        x = x.permute(0, 2, 1) # (batch_size, embed_dim, seq_len)\n",
        "\n",
        "        x1 = F.relu(self.conv3(x)) # Conv1d với kernel_size = 3\n",
        "        x2 = F.relu(self.conv4(x)) # Conv1d với kernel_size = 4\n",
        "        x3 = F.relu(self.conv5(x)) # Conv1d với kernel_size = 5\n",
        "\n",
        "        x1 = F.max_pool1d(x1, x1.size(2)).squeeze(2)\n",
        "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n",
        "        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n",
        "\n",
        "        x = torch.cat((x1, x2, x3), 1) # Nối lại các features\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = torch.sigmoid(self.out(x)) # Binary classification\n",
        "\n",
        "        return x\n",
        "\n",
        "# Model, loss, optimizer\n",
        "model = MultilevelCNN(vocab_size=5000, embed_dim=16).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience = 2\n",
        "wait = 0\n",
        "num_epochs = 20\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\", leave=True)\n",
        "    for batch_X, batch_y in loop:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X).squeeze(1)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # === Validation sau mỗi epoch ===\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    val_loss_total = 0\n",
        "    total = 0\n",
        "    val_loop = tqdm(test_loader, desc=f\"Epoch {epoch+1} [Val]\", leave=True)\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in val_loop:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_X).squeeze(1)\n",
        "            val_loss = criterion(outputs, batch_y)\n",
        "            val_loss_total += val_loss.item()\n",
        "\n",
        "            preds = (outputs > 0.5).float()\n",
        "            correct += (preds == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "            val_loop.set_postfix(val_loss=val_loss.item())\n",
        "\n",
        "    val_acc = correct / total\n",
        "    val_loss_avg = val_loss_total / len(test_loader)\n",
        "    total_loss_avg = total_loss / len(test_loader)\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {total_loss_avg:.4f} | Val Loss: {val_loss_avg:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "    # === Early stopping check ===\n",
        "    if val_loss_avg < best_val_loss:\n",
        "        best_val_loss = val_loss_avg\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break"
      ],
      "metadata": {
        "id": "bjg0PYCK8lid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "def predict_text(texts):\n",
        "    model.eval()\n",
        "    seq = tokenizer.texts_to_sequences(texts)\n",
        "    padded = pad_sequences(seq, maxlen=512, padding='post', truncating='post')\n",
        "    tensor = torch.tensor(padded, dtype=torch.long).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tensor)\n",
        "        probs = outputs.cpu().numpy()\n",
        "        return probs, (probs > 0.5).astype(int)\n",
        "\n",
        "probs, preds = predict_text(X_test)"
      ],
      "metadata": {
        "id": "CJ86o9aT82Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model DL"
      ],
      "metadata": {
        "id": "AUnO7diO76eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tokenizer_and_model(model_name: str, num_labels: int):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    return tokenizer, model"
      ],
      "metadata": {
        "id": "vnbDwTZw62TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "Q-IbcO-P6B_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoaderBuilder:\n",
        "    def __init__(self, dataset, batch_size=32, shuffle=True, num_workers=2):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def get_dataloader(self):\n",
        "        return DataLoader(\n",
        "            dataset=self.dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=self.shuffle,\n",
        "            num_workers=self.num_workers\n",
        "        )"
      ],
      "metadata": {
        "id": "KFc31g3v8DZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, val_loader, model_name, lr=2e-5, epochs=5, patience=2, device='cuda'):\n",
        "        self.model = model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.model_name = model_name\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.patience = patience\n",
        "        self.device = device\n",
        "        self.optimizer = AdamW(self.model.parameters(), lr=lr)\n",
        "        self.scheduler = get_scheduler(\"linear\", self.optimizer, num_warmup_steps=0,\n",
        "                                       num_training_steps=len(train_loader) * epochs)\n",
        "\n",
        "    def train_one_epoch(self):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(self.train_loader, desc=\"Training\"):\n",
        "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "            outputs = self.model(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "            self.optimizer.zero_grad()\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(self.train_loader)\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        all_preds, all_labels = [], []\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(self.val_loader, desc=\"Validating\"):\n",
        "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "                outputs = self.model(**batch)\n",
        "                loss = outputs.loss\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=-1)\n",
        "                total_loss += loss.item()\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(batch['labels'].cpu().numpy())\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        avg_loss = total_loss / len(self.val_loader)\n",
        "        return acc, avg_loss, all_preds, all_labels\n",
        "\n",
        "    def train(self):\n",
        "        best_loss = float('inf')\n",
        "        stop_count = 0\n",
        "        save_path = os.path.join(\"/kaggle/working\", f\"{self.model_name}_best.pt\")\n",
        "\n",
        "        for epoch in range(1, self.epochs + 1):\n",
        "            print(f\"\\nEpoch {epoch}/{self.epochs}\")\n",
        "            train_loss = self.train_one_epoch()\n",
        "            val_acc, val_loss, _, _ = self.evaluate()\n",
        "\n",
        "            print(f\"Train Loss: {train_loss:.4f}\")\n",
        "            print(f\"Val Loss:   {val_loss:.4f} | Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                stop_count = 0\n",
        "                torch.save(self.model.state_dict(), save_path)\n",
        "            else:\n",
        "                stop_count += 1\n",
        "                if stop_count >= self.patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "        self.model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "\n",
        "    def test_model(self, test_loader):\n",
        "        \"\"\"\n",
        "        Đánh giá mô hình trên tập test.\n",
        "        Trả về: accuracy, loss, predicted labels, true labels\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        all_preds, all_labels = [], []\n",
        "        total_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "                batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "                outputs = self.model(**batch)\n",
        "                loss = outputs.loss\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        return acc, avg_loss, all_preds, all_labels\n"
      ],
      "metadata": {
        "id": "keYc2bbk8CfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(model_name, batch_size):\n",
        "    global df, learning_rate, epochs, patience\n",
        "\n",
        "    # print(\"========== SPLIT TRAIN / VAL / TEST ==========\")\n",
        "    # X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    #     df[\"clean_text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
        "    # )\n",
        "    # X_val, X_test, y_val, y_test = train_test_split(\n",
        "    #     X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        "    # )\n",
        "\n",
        "    print(\"========== LOAD TOKENIZER & MODEL ==========\")\n",
        "    tokenizer, model = get_tokenizer_and_model(model_name, num_labels=len(set(df[\"label\"])))\n",
        "\n",
        "    print(\"========== CREATE DATASETS ==========\")\n",
        "    train_dataset = TextClassificationDataset(X_train.tolist(), y_train.tolist(), tokenizer)\n",
        "    val_dataset = TextClassificationDataset(X_val.tolist(), y_val.tolist(), tokenizer)\n",
        "    test_dataset = TextClassificationDataset(X_test.tolist(), y_test.tolist(), tokenizer)\n",
        "\n",
        "    print(\"========== CREATE DATALOADERS ==========\")\n",
        "    train_loader = DataLoaderBuilder(train_dataset, batch_size=batch_size, shuffle=True).get_dataloader()\n",
        "    val_loader = DataLoaderBuilder(val_dataset, batch_size=batch_size, shuffle=False).get_dataloader()\n",
        "    test_loader = DataLoaderBuilder(test_dataset, batch_size=batch_size, shuffle=False).get_dataloader()\n",
        "\n",
        "    print(\"========== INITIALIZE TRAINER ==========\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        model_name=model_name,\n",
        "        lr=learning_rate,\n",
        "        epochs=epochs,\n",
        "        patience=patience,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(f\"\\n{'-'*50}\")\n",
        "    print(f\"\\tTRAINING MODEL: {model_name}\")\n",
        "    print(f\"{'-'*50}\")\n",
        "    train_loss, ... = trainer.train()\n",
        "\n",
        "    print(f\"\\n{'-'*50}\")\n",
        "    print(f\"\\tEVALUATION ON TEST SET\")\n",
        "    print(f\"{'-'*50}\")\n",
        "    test_acc, test_loss, test_preds, test_true_labels = trainer.test_model(test_loader)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(test_true_labels, test_preds, target_names=[str(i) for i in sorted(df['label'].unique())]))\n",
        "\n",
        "    cm = confusion_matrix(test_true_labels, test_preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=sorted(df['label'].unique()),\n",
        "                yticklabels=sorted(df['label'].unique()))\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Test Accuracy: {test_acc:.4f} | Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "csCM3MzT8HMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 2e-5\n",
        "epochs = 5\n",
        "patience = 2"
      ],
      "metadata": {
        "id": "NRGUBqHR8Iln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(model_name=\"bert-base-uncased\", batch_size=64)"
      ],
      "metadata": {
        "id": "bzQXPI5e8Kob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(model_name=\"roberta-base\", batch_size=64)"
      ],
      "metadata": {
        "id": "xPFt6Fuj8MEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(model_name=\"xlnet-base-cased\", batch_size=32)"
      ],
      "metadata": {
        "id": "VelNmI928Opg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_trained_model(model_name, num_labels, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load lại model đã huấn luyện từ file .pt\n",
        "    \"\"\"\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "LJT0QwHI8Qv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thông tin cần\n",
        "model_name = \"roberta-base\"  # ví dụ: bert-base-uncased, xlnet-base-cased,...\n",
        "num_labels = 2\n",
        "checkpoint_path = f\"/kaggle/working/{model_name}_best.pt\"\n",
        "\n",
        "# Load model đã huấn luyện\n",
        "def load_trained_model(model_name, num_labels, checkpoint_path):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model = load_trained_model(model_name, num_labels, checkpoint_path)\n",
        "\n",
        "# Load lại tokenizer và test_loader\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "test_dataset = TextClassificationDataset(\n",
        "    texts=X_test,\n",
        "    labels=y_test,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256\n",
        ")\n",
        "\n",
        "test_loader = DataLoaderBuilder(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=False\n",
        ").get_dataloader()\n",
        "\n",
        "# Đánh giá\n",
        "all_preds, all_labels = [], []\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch['labels'].cpu().numpy())\n"
      ],
      "metadata": {
        "id": "7yshXMKA8TgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thông tin cần\n",
        "model_name = \"xlnet-base-cased\"  # ví dụ: bert-base-uncased, xlnet-base-cased,...\n",
        "num_labels = 2\n",
        "checkpoint_path = f\"/kaggle/working/{model_name}_best.pt\"\n",
        "\n",
        "# Load model đã huấn luyện\n",
        "def load_trained_model(model_name, num_labels, checkpoint_path):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model = load_trained_model(model_name, num_labels, checkpoint_path)\n",
        "\n",
        "# Load lại tokenizer và test_loader\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "test_dataset = TextClassificationDataset(\n",
        "    texts=X_test,\n",
        "    labels=y_test,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256\n",
        ")\n",
        "\n",
        "test_loader = DataLoaderBuilder(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=False\n",
        ").get_dataloader()\n",
        "\n",
        "# Đánh giá\n",
        "all_preds, all_labels = [], []\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch['labels'].cpu().numpy())"
      ],
      "metadata": {
        "id": "mkLA5Okr8U7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.path.exists(\"/kaggle/working/bert-base-uncased_best.pt\")"
      ],
      "metadata": {
        "id": "zhbj3nZD8WWX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}